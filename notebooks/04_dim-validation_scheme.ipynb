{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "central-customs",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-hurricane",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def to_datetime(date):\n",
    "    \"\"\"\n",
    "    Converts a numpy datetime64 object to a python datetime object \n",
    "    Input:\n",
    "      date - a np.datetime64 object\n",
    "    Output:\n",
    "      DATE - a python datetime object\n",
    "    \"\"\"\n",
    "    timestamp = ((date - np.datetime64('1970-01-01T00:00:00')) / np.timedelta64(1, 's'))\n",
    "    return datetime.utcfromtimestamp(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "chubby-springfield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash_tab_num</th>\n",
       "      <th>date</th>\n",
       "      <th>sick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hash_tab_num       date  sick\n",
       "0             0 2015-04-01     0\n",
       "1             0 2015-05-01     0\n",
       "2             0 2015-06-01     0\n",
       "3             0 2015-07-01     0\n",
       "4             0 2015-08-01     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Считывание данных\n",
    "\n",
    "sot = pd.read_csv('sotrudniki.csv', sep = ';')\n",
    "sot['date'] = pd.to_datetime(sot['date'], format='%Y-%m-%d')\n",
    "\n",
    "train_target_df = sot[['hash_tab_num', 'date', 'sick']]\n",
    "train_target_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-gauge",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alternate-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "sot_data = sot[[\n",
    "    'hash_tab_num','date','category','gender','razryad_fact','work_experience_company',\n",
    "    'name_fact_lvl5','education','home_to_work_distance'\n",
    "]]\n",
    "\n",
    "sot_data['gender'] = sot_data['gender'].map(lambda x: 1 if x == 'мужской' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "impaired-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание вспомогательно датасета с информацией о количестве сотрудников в подразделении\n",
    "# по фактическому месту работы\n",
    "\n",
    "division_count = sot_data[['hash_tab_num','date','name_fact_lvl5']].\\\n",
    "groupby(['name_fact_lvl5','date']).agg('count').reset_index()\n",
    "\n",
    "division_count.columns = ['name_fact_lvl5', 'date', 'personel_num']\n",
    "\n",
    "sot_data = pd.merge(sot_data, division_count, how = 'left', on = ['date','name_fact_lvl5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "asian-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание dummy переменных\n",
    "\n",
    "sot_data.education = sot_data['education']\\\n",
    ".map(lambda x: 'Высшее' if x in ['Высшее образование','Высшее-бакалавриат','Высшее-специалитет'] else(\\\n",
    "'Среднее_профессинальное' if x in ['Ср.профессиональное','Нач.профессиональное'] else 'Начальное_среднее'))\n",
    "\n",
    "sot_data = pd.get_dummies(sot_data, columns = ['category','education','razryad_fact']).drop('name_fact_lvl5', axis = 1)\n",
    "sot_data['orig_date'] = sot_data['date'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beneficial-spain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash_tab_num</th>\n",
       "      <th>date</th>\n",
       "      <th>gender</th>\n",
       "      <th>work_experience_company</th>\n",
       "      <th>home_to_work_distance</th>\n",
       "      <th>personel_num</th>\n",
       "      <th>category_Рабочие</th>\n",
       "      <th>category_Руководители</th>\n",
       "      <th>category_Служащие</th>\n",
       "      <th>category_Специалисты</th>\n",
       "      <th>education_Высшее</th>\n",
       "      <th>education_Начальное_среднее</th>\n",
       "      <th>education_Среднее_профессинальное</th>\n",
       "      <th>razryad_fact_0</th>\n",
       "      <th>razryad_fact_1</th>\n",
       "      <th>razryad_fact_2</th>\n",
       "      <th>razryad_fact_3</th>\n",
       "      <th>razryad_fact_4</th>\n",
       "      <th>razryad_fact_5</th>\n",
       "      <th>razryad_fact_6</th>\n",
       "      <th>orig_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-08-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hash_tab_num       date  gender  work_experience_company  \\\n",
       "0             0 2015-04-01       1                      9.0   \n",
       "1             0 2015-05-01       1                      9.0   \n",
       "2             0 2015-06-01       1                      9.0   \n",
       "3             0 2015-07-01       1                      9.0   \n",
       "4             0 2015-08-01       1                      9.0   \n",
       "\n",
       "   home_to_work_distance  personel_num  category_Рабочие  \\\n",
       "0                    NaN           NaN                 1   \n",
       "1                    NaN           NaN                 1   \n",
       "2                    NaN           NaN                 1   \n",
       "3                    NaN           NaN                 1   \n",
       "4                    NaN           NaN                 1   \n",
       "\n",
       "   category_Руководители  category_Служащие  category_Специалисты  \\\n",
       "0                      0                  0                     0   \n",
       "1                      0                  0                     0   \n",
       "2                      0                  0                     0   \n",
       "3                      0                  0                     0   \n",
       "4                      0                  0                     0   \n",
       "\n",
       "   education_Высшее  education_Начальное_среднее  \\\n",
       "0                 0                            1   \n",
       "1                 0                            1   \n",
       "2                 0                            1   \n",
       "3                 0                            1   \n",
       "4                 0                            1   \n",
       "\n",
       "   education_Среднее_профессинальное  razryad_fact_0  razryad_fact_1  \\\n",
       "0                                  0               0               0   \n",
       "1                                  0               0               0   \n",
       "2                                  0               0               0   \n",
       "3                                  0               0               0   \n",
       "4                                  0               0               0   \n",
       "\n",
       "   razryad_fact_2  razryad_fact_3  razryad_fact_4  razryad_fact_5  \\\n",
       "0               0               1               0               0   \n",
       "1               0               1               0               0   \n",
       "2               0               1               0               0   \n",
       "3               0               1               0               0   \n",
       "4               0               1               0               0   \n",
       "\n",
       "   razryad_fact_6  orig_date  \n",
       "0               0 2015-04-01  \n",
       "1               0 2015-05-01  \n",
       "2               0 2015-06-01  \n",
       "3               0 2015-07-01  \n",
       "4               0 2015-08-01  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sot_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "advance-identifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_extra = sot_data[sot_data['orig_date'] == pd.to_datetime('2019-08-01')]\n",
    "submission_extra['target'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-ballot",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "chicken-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('transformed_data/date_of_birth.json', 'r') as f:\n",
    "    date_of_birth_dict = json.load(f)\n",
    "    date_of_birth_dict = {int(k): int(v) for k, v in date_of_birth_dict.items()}\n",
    "\n",
    "\n",
    "def calc_age(hash_tab_num, calc_date, date_of_birth_dict):\n",
    "    cur_date = int(calc_date)\n",
    "    birth_date = date_of_birth_dict[hash_tab_num]\n",
    "    age = cur_date - birth_date\n",
    "    return age\n",
    "\n",
    "\n",
    "with open('transformed_data/relatives_info.json', 'r') as f:\n",
    "    relatives_dict = json.load(f)\n",
    "    relatives_dict = {int(k): v for k, v in relatives_dict.items()}\n",
    "\n",
    "\n",
    "def calc_relatives_bins(hash_tab_num, calc_date, relatives_dict):\n",
    "    '''\n",
    "    bins:\n",
    "        0: 0 - 3: младенец\n",
    "        1: 4 - 7: ребенок\n",
    "        2: 8 - 18: школьник\n",
    "        3: 19 - 35: молодежь :)\n",
    "        4: 36 - 55(F), 60(M): предпенсионный возраст\n",
    "        5: 55(F), 60(M) - +++: пенсионер\n",
    "        6: кол-во родственников мужского рода\n",
    "        7: кол-во родственников женского рода\n",
    "    '''\n",
    "    \n",
    "    bins = [0] * 8\n",
    "    if hash_tab_num not in relatives_dict:\n",
    "        return bins\n",
    "    \n",
    "    cur_date = int(calc_date)\n",
    "    for (sex, birth_date) in relatives_dict[hash_tab_num]:\n",
    "        if sex == 'M':\n",
    "            bins[6] += 1\n",
    "        elif sex == 'F':\n",
    "            bins[7] += 1\n",
    "            \n",
    "        if birth_date < 0:\n",
    "            continue\n",
    "            \n",
    "        age = cur_date - birth_date\n",
    "        if age < 0:\n",
    "            continue\n",
    "        elif age <= 3:\n",
    "            bins[0] += 1\n",
    "        elif age <= 7:\n",
    "            bins[1] += 1\n",
    "        elif age <= 18:\n",
    "            bins[2] += 1\n",
    "        elif age <= 35:\n",
    "            bins[3] += 1\n",
    "        else:\n",
    "            if (sex == 'M' and age >= 60) or (sex == 'F' and age >= 55):\n",
    "                bins[5] += 1\n",
    "            else:\n",
    "                bins[4] += 1\n",
    "    return bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "informational-fundamental",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_date_features(df):\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['age'] = df.apply(lambda x: calc_age(x['hash_tab_num'], x['year'], date_of_birth_dict), axis=1)\n",
    "    df['is_pensioner'] = (((df['age'] >= 60) & (df['gender'] == 1)) | ((df['age'] >= 55) & (df['gender'] == 0))).astype(int)\n",
    "    df['relatives'] = df.apply(lambda x: calc_relatives_bins(x['hash_tab_num'], x['year'], relatives_dict), axis=1)\n",
    "    for i in range(8):\n",
    "        df[f'relatives_{i}'] = df['relatives'].apply(lambda x: x[i])\n",
    "    df = df.drop(columns=['year', 'relatives'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-binary",
   "metadata": {},
   "source": [
    "## 1 Month model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "environmental-investing",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = 1\n",
    "check_shift = 1\n",
    "prediction_dates = sorted(sot_data['orig_date'].unique())[:-(months + check_shift)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "southeast-formula",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/54 0.6511155302039179\n",
      "2/54 0.6545483767277404\n",
      "3/54 0.5645284300878453\n",
      "4/54 0.6877272727272727\n",
      "5/54 0.6792152168129822\n",
      "6/54 0.6573453557891447\n",
      "7/54 0.6981771590206681\n",
      "8/54 0.6774611881212693\n",
      "9/54 0.6663067552602436\n",
      "10/54 0.6923417590872412\n",
      "11/54 0.6317884228475865\n",
      "12/54 0.6975479744136461\n",
      "13/54 0.6481928736341487\n",
      "14/54 0.668122157088859\n",
      "15/54 0.6855188712637293\n",
      "16/54 0.6455491996587887\n",
      "17/54 0.692638663262938\n",
      "18/54 0.6808885596264367\n",
      "19/54 0.6530021836224355\n",
      "20/54 0.6479178716020821\n",
      "21/54 0.6611764287365931\n",
      "22/54 0.6782167895223282\n",
      "23/54 0.6613863636363637\n",
      "24/54 0.7037440042052697\n",
      "25/54 0.6638358250276855\n",
      "26/54 0.6925992341944315\n",
      "27/54 0.6506002250016545\n",
      "28/54 0.7026553220277241\n",
      "29/54 0.6702271584624526\n",
      "30/54 0.667213256801962\n",
      "31/54 0.6490829943623777\n",
      "32/54 0.6618747623590376\n",
      "33/54 0.6840862412686617\n",
      "34/54 0.6590831180744997\n",
      "35/54 0.65755245814711\n",
      "36/54 0.7240151363657341\n",
      "37/54 0.7045324285539281\n",
      "38/54 0.6770011534996505\n",
      "39/54 0.6565502022643208\n",
      "40/54 0.6796352636471648\n",
      "41/54 0.6593549623051871\n",
      "42/54 0.7064462840256236\n",
      "43/54 0.6706946102489278\n",
      "44/54 0.6910750195262112\n",
      "45/54 0.6737893252110632\n",
      "46/54 0.672816896587136\n",
      "47/54 0.661169882633224\n",
      "48/54 0.6999335374682524\n",
      "49/54 0.738859297384643\n",
      "50/54 0.675208555200568\n",
      "51/54 0.6829771795408024\n",
      "52/54 0.6795509631330527\n",
      "53/54 0.7063615608136156\n",
      "54/54 0.7036538320498715\n"
     ]
    }
   ],
   "source": [
    "for idx, prediction_date in enumerate(prediction_dates):\n",
    "    \n",
    "    df_train = sot_data[sot_data['orig_date'] <= prediction_date].copy()\n",
    "    df_train['date'] = df_train['orig_date'] + pd.DateOffset(months=months)\n",
    "    df_train = pd.merge(df_train, train_target_df, on=['hash_tab_num', 'date'])\n",
    "    \n",
    "    test_date = to_datetime(prediction_date) + relativedelta(months=check_shift)\n",
    "    df_test = sot_data[sot_data['orig_date'] == test_date].copy()\n",
    "    df_test['date'] = df_test['orig_date'] + pd.DateOffset(months=months)\n",
    "    df_test = pd.merge(df_test, train_target_df, on=['hash_tab_num', 'date'])\n",
    "\n",
    "    df_train = target_date_features(df_train)\n",
    "    df_test = target_date_features(df_test)\n",
    "    \n",
    "    X_train = df_train.drop(columns=['hash_tab_num', 'date', 'orig_date', 'sick']).fillna(-100)\n",
    "    X_test = df_test.drop(columns=['hash_tab_num', 'date', 'orig_date', 'sick']).fillna(-100)\n",
    "    \n",
    "    y_train = df_train['sick']\n",
    "    y_test = df_test['sick']\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict_proba(X_test)[:, 1]\n",
    "    score = roc_auc_score(y_test, preds)\n",
    "    \n",
    "    print(f'{idx + 1}/{len(prediction_dates)}', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-lawyer",
   "metadata": {},
   "source": [
    "## 2 Months model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "special-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = 2\n",
    "check_shift = 1\n",
    "prediction_dates = sorted(sot_data['orig_date'].unique())[:-(months + check_shift)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "neither-disco",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/53 0.619779524713111\n",
      "2/53 0.6050254486077091\n",
      "3/53 0.6221172370806891\n",
      "4/53 0.6985824558676873\n",
      "5/53 0.6386934326710817\n",
      "6/53 0.6854657687991021\n",
      "7/53 0.6759918463036864\n",
      "8/53 0.6839781271360217\n",
      "9/53 0.6867372940869599\n",
      "10/53 0.6439135184865735\n",
      "11/53 0.6963285606631499\n",
      "12/53 0.6422720563390302\n",
      "13/53 0.6884239360489728\n",
      "14/53 0.7042754813548336\n",
      "15/53 0.6433444722918408\n",
      "16/53 0.6844676533664157\n",
      "17/53 0.7032806339241281\n",
      "18/53 0.6399026148010313\n",
      "19/53 0.6444176681358403\n",
      "20/53 0.6559602597923512\n",
      "21/53 0.6909033322178133\n",
      "22/53 0.6509112313448701\n",
      "23/53 0.6853677224439936\n",
      "24/53 0.6644593161560287\n",
      "25/53 0.6945996496046215\n",
      "26/53 0.6580794854855014\n",
      "27/53 0.7156558638955209\n",
      "28/53 0.6825446651674163\n",
      "29/53 0.6662282780945673\n",
      "30/53 0.6601027063862928\n",
      "31/53 0.6718166146391464\n",
      "32/53 0.6819306419821884\n",
      "33/53 0.6600112177489716\n",
      "34/53 0.6624408738607404\n",
      "35/53 0.7060436909174653\n",
      "36/53 0.7059539297643432\n",
      "37/53 0.6689178256107275\n",
      "38/53 0.659558178752108\n",
      "39/53 0.6952584315602626\n",
      "40/53 0.6683592353023495\n",
      "41/53 0.6963990740740742\n",
      "42/53 0.6870428337706326\n",
      "43/53 0.6897310430516777\n",
      "44/53 0.6771440688079651\n",
      "45/53 0.6665613784285793\n",
      "46/53 0.6639974042829332\n",
      "47/53 0.6803161966970908\n",
      "48/53 0.7291997513488837\n",
      "49/53 0.692585305815589\n",
      "50/53 0.6758251078593283\n",
      "51/53 0.6812402181415198\n",
      "52/53 0.7158608014822341\n",
      "53/53 0.7351046255506607\n"
     ]
    }
   ],
   "source": [
    "for idx, prediction_date in enumerate(prediction_dates):\n",
    "    \n",
    "    df_train = sot_data[sot_data['orig_date'] <= prediction_date].copy()\n",
    "    df_train['date'] = df_train['orig_date'] + pd.DateOffset(months=months)\n",
    "    df_train = pd.merge(df_train, train_target_df, on=['hash_tab_num', 'date'])\n",
    "    \n",
    "    test_date = to_datetime(prediction_date) + relativedelta(months=check_shift)\n",
    "    df_test = sot_data[sot_data['orig_date'] == test_date].copy()\n",
    "    df_test['date'] = df_test['orig_date'] + pd.DateOffset(months=months)\n",
    "    df_test = pd.merge(df_test, train_target_df, on=['hash_tab_num', 'date'])\n",
    "    \n",
    "    \n",
    "    df_train = target_date_features(df_train)\n",
    "    df_test = target_date_features(df_test)\n",
    "    \n",
    "    X_train = df_train.drop(columns=['hash_tab_num', 'date', 'orig_date', 'sick']).fillna(-100)\n",
    "    X_test = df_test.drop(columns=['hash_tab_num', 'date', 'orig_date', 'sick']).fillna(-100)\n",
    "    \n",
    "    y_train = df_train['sick']\n",
    "    y_test = df_test['sick']\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict_proba(X_test)[:, 1]\n",
    "    score = roc_auc_score(y_test, preds)\n",
    "    \n",
    "    print(f'{idx + 1}/{len(prediction_dates)}', score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
